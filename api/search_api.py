#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½æ£€ç´¢ç³»ç»ŸAPIæ¥å£
æä¾›RESTful APIå’Œå‘½ä»¤è¡Œæ¥å£
"""

import argparse
import json
import sys
from pathlib import Path
from typing import Dict, Any, Optional, List

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥ä¾¿å¯¼å…¥coreæ¨¡å—
sys.path.append(str(Path(__file__).parent.parent))

from core.search_engine import IntelligentSearchEngine
from core.document_generator import DocumentGenerator


class SearchAPI:
    """æœç´¢APIæ¥å£"""

    def __init__(self, knowledge_base_dir: str = "knowledge_base",
                 search_paths: List[str] = None,
                 config_path: str = "config/config.json",
                 output_dir: str = "output"):
        """
        åˆå§‹åŒ–API

        Args:
            knowledge_base_dir: çŸ¥è¯†åº“æ ¹ç›®å½•
            search_paths: æœç´¢è·¯å¾„åˆ—è¡¨
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
        """
        self.engine = IntelligentSearchEngine(knowledge_base_dir, search_paths, config_path)
        self.generator = DocumentGenerator(output_dir)

    def search(self, query: str, search_type: str = "all",
               max_results: int = 50, format_type: str = "summary",
               save_file: bool = False, include_full_content: bool = False) -> Dict[str, Any]:
        """
        æ‰§è¡Œæœç´¢

        Args:
            query: æœç´¢å…³é”®è¯
            search_type: æœç´¢ç±»å‹ ('filename', 'content', 'tag', 'all')
            max_results: æœ€å¤§ç»“æœæ•°
            format_type: è¾“å‡ºæ ¼å¼ ('summary', 'detailed', 'thematic', 'full_content', 'html', 'json')
            save_file: æ˜¯å¦ä¿å­˜åˆ°æ–‡ä»¶
            include_full_content: æ˜¯å¦åŒ…å«å®Œæ•´åŸæ–‡å†…å®¹

        Returns:
            Dict: æœç´¢ç»“æœ
        """
        print(f"ğŸ” æœç´¢å…³é”®è¯: '{query}'")
        print(f"ğŸ“ çŸ¥è¯†åº“ç›®å½•: {self.engine.knowledge_base_dir}")
        print(f"ğŸ“‚ æœç´¢è·¯å¾„: {self.engine.search_paths}")
        print(f"ğŸ” æœç´¢ç±»å‹: {search_type}")
        if include_full_content:
            print(f"ğŸ“„ åŒ…å«å®Œæ•´åŸæ–‡å†…å®¹")
        print("-" * 50)

        # æ‰§è¡Œæœç´¢
        results = self.engine.search(query, search_type, max_results, include_full_content)

        print(f"âœ… æ‰¾åˆ° {len(results)} ä¸ªç»“æœ")

        if not results:
            return {
                "success": True,
                "query": query,
                "search_type": search_type,
                "total_results": 0,
                "results": [],
                "content": "æœªæ‰¾åˆ°ç›¸å…³ç»“æœ",
                "saved_file": None
            }

        # ç”Ÿæˆè¾“å‡º
        if format_type == "html":
            content = self.generator.generate_html(results, query, include_full_content)
            output_format = "html"
        elif format_type == "json":
            content = self.generator.generate_json(results, query, include_full_content=include_full_content)
            output_format = "json"
        else:
            content = self.generator.generate_markdown(results, query, format_type, include_full_content)
            output_format = "markdown"

        # ä¿å­˜æ–‡ä»¶
        saved_file = None
        if save_file:
            safe_query = "".join(c for c in query if c.isalnum() or c in (' ', '-', '_')).rstrip()
            filename = f"search_{safe_query}_{format_type}"
            saved_file = self.generator.save_document(content, filename, output_format)
            print(f"ğŸ’¾ å·²ä¿å­˜åˆ°: {saved_file}")

        return {
            "success": True,
            "query": query,
            "search_type": search_type,
            "total_results": len(results),
            "results": results,
            "content": content,
            "saved_file": saved_file
        }

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        return self.engine.get_stats()

    def rebuild_index(self) -> Dict[str, Any]:
        """é‡å»ºç´¢å¼•"""
        print("ğŸ”„ é‡å»ºç´¢å¼•ä¸­...")
        index = self.engine.build_index()
        print("âœ… ç´¢å¼•é‡å»ºå®Œæˆ")
        return {"success": True, "index": index}

    def get_search_profiles(self) -> Dict[str, Any]:
        """è·å–æœç´¢é…ç½®æ–‡ä»¶åˆ—è¡¨"""
        return self.engine.get_search_profiles()

    def use_search_profile(self, profile_name: str) -> Dict[str, Any]:
        """ä½¿ç”¨æŒ‡å®šçš„æœç´¢é…ç½®æ–‡ä»¶"""
        try:
            self.engine.use_search_profile(profile_name)
            return {"success": True, "profile": profile_name}
        except Exception as e:
            return {"success": False, "error": str(e)}

    def set_search_paths(self, paths: List[str]) -> Dict[str, Any]:
        """è®¾ç½®è‡ªå®šä¹‰æœç´¢è·¯å¾„"""
        try:
            self.engine.set_search_paths(paths)
            return {"success": True, "paths": paths}
        except Exception as e:
            return {"success": False, "error": str(e)}


def main():
    """å‘½ä»¤è¡Œæ¥å£"""
    parser = argparse.ArgumentParser(description="æ™ºèƒ½æ£€ç´¢ç³»ç»Ÿ")
    parser.add_argument("query", nargs="?", help="æœç´¢å…³é”®è¯")
    parser.add_argument("-t", "--type", choices=["filename", "content", "tag", "all"],
                       default="all", help="æœç´¢ç±»å‹")
    parser.add_argument("-n", "--max-results", type=int, default=50,
                       help="æœ€å¤§ç»“æœæ•°")
    parser.add_argument("-f", "--format", choices=["summary", "detailed", "thematic", "full_content", "html", "json"],
                       default="summary", help="è¾“å‡ºæ ¼å¼")
    parser.add_argument("-s", "--save", action="store_true", help="ä¿å­˜åˆ°æ–‡ä»¶")
    parser.add_argument("--full-content", action="store_true", help="åŒ…å«å®Œæ•´åŸæ–‡å†…å®¹")
    parser.add_argument("-d", "--knowledge-base-dir", default="knowledge_base", help="çŸ¥è¯†åº“æ ¹ç›®å½•è·¯å¾„")
    parser.add_argument("-p", "--search-paths", nargs="+", help="æœç´¢è·¯å¾„åˆ—è¡¨ï¼ˆç›¸å¯¹äºçŸ¥è¯†åº“æ ¹ç›®å½•ï¼‰")
    parser.add_argument("-c", "--config", default="config/config.json", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("-o", "--output-dir", default="output", help="è¾“å‡ºç›®å½•è·¯å¾„")
    parser.add_argument("--stats", action="store_true", help="æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯")
    parser.add_argument("--rebuild", action="store_true", help="é‡å»ºç´¢å¼•")
    parser.add_argument("--profiles", action="store_true", help="æ˜¾ç¤ºæœç´¢é…ç½®æ–‡ä»¶")
    parser.add_argument("--profile", help="ä½¿ç”¨æŒ‡å®šçš„æœç´¢é…ç½®æ–‡ä»¶")
    parser.add_argument("--list-paths", action="store_true", help="æ˜¾ç¤ºå½“å‰æœç´¢è·¯å¾„")

    args = parser.parse_args()

    # åˆå§‹åŒ–API
    api = SearchAPI(args.knowledge_base_dir, args.search_paths, args.config, args.output_dir)

    # å¤„ç†ç‰¹æ®Šå‘½ä»¤
    # æ˜¾ç¤ºæœç´¢é…ç½®æ–‡ä»¶
    if args.profiles:
        profiles = api.get_search_profiles()
        print("\nğŸ“‹ æœç´¢é…ç½®æ–‡ä»¶")
        print("=" * 40)
        for profile_id, profile_info in profiles.items():
            print(f"â€¢ {profile_id}: {profile_info.get('name', profile_id)}")
            print(f"  è·¯å¾„: {', '.join(profile_info.get('paths', []))}")
            print(f"  æè¿°: {profile_info.get('description', 'æ— æè¿°')}")
            print()
        return

    # ä½¿ç”¨æœç´¢é…ç½®æ–‡ä»¶
    if args.profile:
        result = api.use_search_profile(args.profile)
        if result["success"]:
            print(f"âœ… {result['message']}")
        else:
            print(f"âŒ åˆ‡æ¢é…ç½®å¤±è´¥: {result['error']}")
        return

    # æ˜¾ç¤ºå½“å‰æœç´¢è·¯å¾„
    if args.list_paths:
        print(f"\nğŸ“‚ å½“å‰æœç´¢è·¯å¾„: {api.engine.search_paths}")
        print(f"ğŸ“ çŸ¥è¯†åº“æ ¹ç›®å½•: {api.engine.knowledge_base_dir}")
        return

    if args.stats:
        stats = api.get_stats()
        print("\nğŸ“Š ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯")
        print("=" * 50)
        print(f"ğŸ“ çŸ¥è¯†åº“æ ¹ç›®å½•: {api.engine.knowledge_base_dir}")
        print(f"ğŸ“‚ æœç´¢è·¯å¾„: {', '.join(api.engine.search_paths)}")
        print(f"ğŸ“„ æ€»æ–‡ä»¶æ•°: {stats['total_files']:,}")
        print(f"ğŸ“ æ€»å­—æ•°: {stats['total_words']:,}")
        print(f"ğŸ•’ æœ€åç´¢å¼•æ—¶é—´: {stats['last_index_time']}")
        print("\næ–‡ä»¶ç±»å‹åˆ†å¸ƒ:")
        for ext, count in stats['file_types'].items():
            print(f"  {ext or 'æ— æ‰©å±•å'}: {count}")
        print("\nç›®å½•åˆ†å¸ƒ:")
        for category, count in sorted(stats['categories'].items()):
            print(f"  {category}: {count}")
        return

    if args.rebuild:
        api.rebuild_index()
        return

    # æ£€æŸ¥æ˜¯å¦æä¾›äº†æœç´¢å…³é”®è¯
    if not args.query:
        parser.print_help()
        print("\nâŒ è¯·æä¾›æœç´¢å…³é”®è¯")
        return

    # æ‰§è¡Œæœç´¢
    result = api.search(
        query=args.query,
        search_type=args.type,
        max_results=args.max_results,
        format_type=args.format,
        save_file=args.save,
        include_full_content=args.full_content
    )

    # æ˜¾ç¤ºç»“æœ
    if result["success"]:
        if args.format == "json":
            print(json.dumps(result["content"], ensure_ascii=False, indent=2))
        else:
            print("\n" + result["content"])
    else:
        print(f"âŒ æœç´¢å¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")


if __name__ == "__main__":
    main()